{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "import clip\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import data_utils\n",
    "from torchvision import transforms\n",
    "import similarity\n",
    "import utils\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PM_SUFFIX = {\"max\":\"_max\", \"avg\":\"\"}\n",
    "\n",
    "def _make_save_dir(save_name):\n",
    "    \"\"\"\n",
    "    creates save directory if one does not exist\n",
    "    save_name: full save path\n",
    "    \"\"\"\n",
    "    save_dir = save_name[:save_name.rfind(\"/\")]\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "def get_save_names(clip_name, target_name, target_layer, d_probe, concept_set, pool_mode, save_dir):\n",
    "    \n",
    "    target_save_name = \"{}/{}_{}_{}{}.pt\".format(save_dir, d_probe, target_name, target_layer,\n",
    "                                             PM_SUFFIX[pool_mode])\n",
    "    clip_save_name = \"{}/{}_{}.pt\".format(save_dir, d_probe, clip_name.replace('/', ''))\n",
    "    concept_set_name = (concept_set.split(\"/\")[-1]).split(\".\")[0]\n",
    "    text_save_name = \"{}/{}_{}.pt\".format(save_dir, concept_set_name, clip_name.replace('/', ''))\n",
    "    \n",
    "    return target_save_name, clip_save_name, text_save_name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_clip_image_features(model, dataset, save_name, batch_size=1000 , device = \"mps\"):\n",
    "    _make_save_dir(save_name)\n",
    "    \n",
    "    all_features = []\n",
    "    \n",
    "    if os.path.exists(save_name):\n",
    "        return\n",
    "    \n",
    "    save_dir = save_name[:save_name.rfind(\"/\")]\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            for images in tqdm(DataLoader(dataset, batch_size, num_workers=8, pin_memory=True)):\n",
    "                features = model.encode_image(images.to(device))\n",
    "                all_features.append(features)\n",
    "    \n",
    "    except:\n",
    "        print(\"Couldn't do for images in tqdm(Dataloader)\")\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(DataLoader(dataset, batch_size, num_workers=8, pin_memory=True)):\n",
    "                features = model.encode_image(images.to(device))\n",
    "                all_features.append(features)\n",
    "    torch.save(torch.cat(all_features), save_name)\n",
    "    #free memory\n",
    "    del all_features\n",
    "    torch.cuda.empty_cache()\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_target_activations(target_model, dataset, save_name, target_layers = [\"layer4\"], batch_size = 1000,\n",
    "                            device = \"cuda\", pool_mode='avg'):\n",
    "    \"\"\"\n",
    "    save_name: save_file path, should include {} which will be formatted by layer names\n",
    "    \"\"\"\n",
    "    _make_save_dir(save_name)\n",
    "    save_names = {}    \n",
    "    for target_layer in target_layers:\n",
    "        save_names[target_layer] = save_name.format(target_layer)\n",
    "        \n",
    "    if _all_saved(save_names):\n",
    "        return\n",
    "    \n",
    "    all_features = {target_layer:[] for target_layer in target_layers}\n",
    "    \n",
    "    hooks = {}\n",
    "    for target_layer in target_layers:\n",
    "        command = \"target_model.{}.register_forward_hook(get_activation(all_features[target_layer], pool_mode))\".format(target_layer)\n",
    "        hooks[target_layer] = eval(command)\n",
    "    \n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            for images in tqdm(DataLoader(dataset, batch_size, num_workers=8, pin_memory=True)):\n",
    "                features = target_model(images.to(device))\n",
    "    except:\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(DataLoader(dataset, batch_size, num_workers=8, pin_memory=True)):\n",
    "                features = target_model(images.to(device))\n",
    "    \n",
    "    for target_layer in target_layers:\n",
    "        torch.save(torch.cat(all_features[target_layer]), save_names[target_layer])\n",
    "        hooks[target_layer].remove()\n",
    "    #free memory\n",
    "    del all_features\n",
    "    torch.cuda.empty_cache()\n",
    "    return\n",
    "\n",
    "\n",
    "def _all_saved(save_names):\n",
    "    \"\"\"\n",
    "    save_names: {layer_name:save_path} dict\n",
    "    Returns True if there is a file corresponding to each one of the values in save_names,\n",
    "    else Returns False\n",
    "    \"\"\"\n",
    "    for save_name in save_names.values():\n",
    "        if not os.path.exists(save_name):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation(outputs, mode):\n",
    "    '''\n",
    "    mode: how to pool activations: one of avg, max\n",
    "    for fc or ViT neurons does no pooling\n",
    "    '''\n",
    "    if mode=='avg':\n",
    "        def hook(model, input, output):\n",
    "            if len(output.shape)==4: #CNN layers\n",
    "                outputs.append(output.mean(dim=[2,3]).detach())\n",
    "            elif len(output.shape)==3: #ViT\n",
    "                outputs.append(output[:, 0].clone())\n",
    "            elif len(output.shape)==2: #FC layers\n",
    "                outputs.append(output.detach())\n",
    "    elif mode=='max':\n",
    "        def hook(model, input, output):\n",
    "            if len(output.shape)==4: #CNN layers\n",
    "                outputs.append(output.amax(dim=[2,3]).detach())\n",
    "            elif len(output.shape)==3: #ViT\n",
    "                outputs.append(output[:, 0].clone())\n",
    "            elif len(output.shape)==2: #FC layers\n",
    "                outputs.append(output.detach())\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1233277792.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[8], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    python3 describe_neurons.py --clip_model 'ViT-B/16' --target_model 'resnet18_places' --target_layers \"layer16,layer17,layer18\" --d_probe \"imagenet\"\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# python3 describe_neurons.py --clip_model 'ViT-B/16' --target_model 'resnet18_places' --target_layers \"layer16,layer17,layer18\" --d_probe \"imagenet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.save_activations(clip_name = args.clip_model, target_name = args.target_model, \n",
    "#                         target_layers = args.target_layers, d_probe = args.d_probe, \n",
    "#                         concept_set = args.concept_set, batch_size = args.batch_size, \n",
    "#                         device = args.device, pool_mode=args.pool_mode, \n",
    "#                         save_dir = args.activation_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layers = 'layer3,layer4,fc'.split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['layer3', 'layer4', 'fc']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_fn = eval(\"similarity.{}\".format('soft_wpmi')) #soft_wpmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_model = 'ViT-B/16'\n",
    "target_model = 'resnet50_imagenet'\n",
    "target_layers = target_layers\n",
    "d_probe = 'imagenet'\n",
    "concept_set = 'data/20k.txt'\n",
    "batch_size = 5\n",
    "device = 'mps'\n",
    "pool_mode='avg'\n",
    "save_dir = 'saved_activations'\n",
    "activation_dir = 'saved_activations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running utils.save_activations\n",
      "Loading CLIP and preprocess model\n",
      "Loading Target and preprocess model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /Users/nursulusagimbayeva/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
      "100%|██████████| 97.8M/97.8M [00:18<00:00, 5.53MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting d_probe data\n",
      "Error processing file .DS_Store: cannot identify image file '/Users/nursulusagimbayeva/Downloads/TrustworthyML-24/neural_networks_explainability/Assignment_4/imagenet/.DS_Store'\n",
      "Error processing file .DS_Store: cannot identify image file '/Users/nursulusagimbayeva/Downloads/TrustworthyML-24/neural_networks_explainability/Assignment_4/imagenet/.DS_Store'\n",
      "Tokenizing words\n",
      "Running get_save_names\n",
      "Saving CLIP text, image features and target activations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:03<?, ?it/s]\n",
      "100%|██████████| 200/200 [00:11<00:00, 17.57it/s]\n"
     ]
    }
   ],
   "source": [
    "print('Running utils.save_activations')\n",
    "utils.save_activations(clip_name = 'ViT-B/16', target_name = target_model, \n",
    "                           target_layers = target_layers, d_probe = 'imagenet', \n",
    "                           concept_set = 'data/20k.txt', batch_size = batch_size, \n",
    "                           device = 'mps', pool_mode='avg', \n",
    "                           save_dir = 'saved_activations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = {\"layer\":[], \"unit\":[], \"description\":[], \"similarity\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(concept_set, 'r') as f: \n",
    "        words = (f.read()).split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function similarity.soft_wpmi(clip_feats, target_feats, top_k=50, a=10, lam=1, device='mps', min_prob=1e-07, p_start=0.998, p_end=0.97)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for target_layer in target_layers:\n",
      "layer3\n",
      "('saved_activations/imagenet_resnet50_imagenet_layer3.pt', 'saved_activations/imagenet_ViT-B16.pt', 'saved_activations/20k_ViT-B16.pt')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:02<00:00, 401.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 20000])\n",
      "layer4\n",
      "('saved_activations/imagenet_resnet50_imagenet_layer4.pt', 'saved_activations/imagenet_ViT-B16.pt', 'saved_activations/20k_ViT-B16.pt')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:04<00:00, 480.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048, 20000])\n",
      "fc\n",
      "('saved_activations/imagenet_resnet50_imagenet_fc.pt', 'saved_activations/imagenet_ViT-B16.pt', 'saved_activations/20k_ViT-B16.pt')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 452.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 20000])\n"
     ]
    }
   ],
   "source": [
    "print('Running for target_layer in target_layers:')\n",
    "for target_layer in target_layers:\n",
    "    print(target_layer)\n",
    "    save_names = utils.get_save_names(clip_name = clip_model, target_name = target_model,\n",
    "                                target_layer = target_layer, d_probe = d_probe,\n",
    "                                concept_set = concept_set, pool_mode = pool_mode,\n",
    "                                save_dir = activation_dir)\n",
    "    target_save_name, clip_save_name, text_save_name = save_names\n",
    "    print(save_names)\n",
    "\n",
    "    similarities = utils.get_similarity_from_activations(\n",
    "        target_save_name, clip_save_name, text_save_name, similarity_fn, return_target_feats=False, device=device\n",
    "    )\n",
    "    \n",
    "    vals, ids = torch.max(similarities, dim=1)\n",
    "        \n",
    "    del similarities\n",
    "    # torch.cuda.empty_cache()\n",
    "    \n",
    "    descriptions = [words[int(idx)] for idx in ids]\n",
    "    \n",
    "    outputs[\"unit\"].extend([i for i in range(len(vals))])\n",
    "    outputs[\"layer\"].extend([target_layer]*len(vals))\n",
    "    outputs[\"description\"].extend(descriptions)\n",
    "    outputs[\"similarity\"].extend(vals.cpu().numpy())\n",
    "\n",
    "\n",
    "   \n",
    "    \n",
    "   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = 'results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df = pd.DataFrame(outputs)\n"
     ]
    }
   ],
   "source": [
    "print('df = pd.DataFrame(outputs)')\n",
    "df = pd.DataFrame(outputs)\n",
    "if not os.path.exists(result_dir):\n",
    "    os.mkdir(result_dir)\n",
    "save_path = \"{}/{}_{}\".format(result_dir, target_model, datetime.datetime.now().strftime(\"%y_%m_%d_%H_%M\"))\n",
    "os.mkdir(save_path)\n",
    "df.to_csv(os.path.join(save_path,\"descriptions.csv\"), index=False)\n",
    "# with open(os.path.join(save_path, \"txt\"), 'w') as f:\n",
    "#     json.dump(__dict__, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>unit</th>\n",
       "      <th>description</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>layer3</td>\n",
       "      <td>0</td>\n",
       "      <td>nature</td>\n",
       "      <td>0.072968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>layer3</td>\n",
       "      <td>1</td>\n",
       "      <td>cookbook</td>\n",
       "      <td>0.063263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>layer3</td>\n",
       "      <td>2</td>\n",
       "      <td>wildlife</td>\n",
       "      <td>0.069534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>layer3</td>\n",
       "      <td>3</td>\n",
       "      <td>crab</td>\n",
       "      <td>0.052734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>layer3</td>\n",
       "      <td>4</td>\n",
       "      <td>birding</td>\n",
       "      <td>0.111649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4067</th>\n",
       "      <td>fc</td>\n",
       "      <td>995</td>\n",
       "      <td>fungi</td>\n",
       "      <td>0.132950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4068</th>\n",
       "      <td>fc</td>\n",
       "      <td>996</td>\n",
       "      <td>fungi</td>\n",
       "      <td>0.129318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4069</th>\n",
       "      <td>fc</td>\n",
       "      <td>997</td>\n",
       "      <td>mushroom</td>\n",
       "      <td>0.120590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4070</th>\n",
       "      <td>fc</td>\n",
       "      <td>998</td>\n",
       "      <td>corn</td>\n",
       "      <td>0.107513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4071</th>\n",
       "      <td>fc</td>\n",
       "      <td>999</td>\n",
       "      <td>bathroom</td>\n",
       "      <td>0.095932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4072 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       layer  unit description  similarity\n",
       "0     layer3     0      nature    0.072968\n",
       "1     layer3     1    cookbook    0.063263\n",
       "2     layer3     2    wildlife    0.069534\n",
       "3     layer3     3        crab    0.052734\n",
       "4     layer3     4     birding    0.111649\n",
       "...      ...   ...         ...         ...\n",
       "4067      fc   995       fungi    0.132950\n",
       "4068      fc   996       fungi    0.129318\n",
       "4069      fc   997    mushroom    0.120590\n",
       "4070      fc   998        corn    0.107513\n",
       "4071      fc   999    bathroom    0.095932\n",
       "\n",
       "[4072 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = pd.read_csv(\"/Users/nursulusagimbayeva/Downloads/TrustworthyML-24/neural_networks_explainability/Assignment_4/results/resnet18_imagenet_24_07_25_19_50/descriptions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = pd.read_csv(\"/Users/nursulusagimbayeva/Downloads/TrustworthyML-24/neural_networks_explainability/Assignment_4/results/resnet18_places_24_07_25_19_42/descriptions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_tuples = list(zip(list(outputs['layer']), list(outputs['unit']), list(outputs['description']), list(outputs['similarity'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('layer3', 0, 'locked', 0.048675537)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_tuples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Filter tuples where the first element is 'layer'\n",
    "layer_tuples = [t for t in outputs_tuples if t[0] == 'fc']\n",
    "\n",
    "# Step 2: Sort the filtered tuples by the last element in descending order\n",
    "sorted_layer_tuples = sorted(layer_tuples, key=lambda x: x[-1], reverse=True)\n",
    "\n",
    "# Step 3: Select the top 50 tuples\n",
    "top_50_layer_tuples = sorted_layer_tuples[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts_learned = Counter([el[2] for el in top_50_layer_tuples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'wildlife': 13,\n",
       "         'bedroom': 7,\n",
       "         'food': 6,\n",
       "         'car': 5,\n",
       "         'ferries': 3,\n",
       "         'dog': 2,\n",
       "         'nature': 2,\n",
       "         'insect': 1,\n",
       "         'insects': 1,\n",
       "         'vehicle': 1,\n",
       "         'juvenile': 1,\n",
       "         'foods': 1,\n",
       "         'deg': 1,\n",
       "         'bookshelf': 1,\n",
       "         'vehicles': 1,\n",
       "         'desert': 1,\n",
       "         'sailing': 1,\n",
       "         'vendors': 1,\n",
       "         'beverage': 1})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concepts_learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_probs = max([el[3] for el in top_50_layer_tuples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14938354"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fc', 142, 'wildlife', 0.14938354),\n",
       " ('fc', 52, 'bedroom', 0.14700317),\n",
       " ('fc', 363, 'bedroom', 0.14633179),\n",
       " ('fc', 124, 'bedroom', 0.14356995),\n",
       " ('fc', 62, 'insect', 0.14224243),\n",
       " ('fc', 150, 'wildlife', 0.13961792),\n",
       " ('fc', 346, 'dog', 0.13885498),\n",
       " ('fc', 104, 'wildlife', 0.13664246),\n",
       " ('fc', 279, 'wildlife', 0.13616943),\n",
       " ('fc', 267, 'food', 0.1361084),\n",
       " ('fc', 51, 'bedroom', 0.1352539),\n",
       " ('fc', 3, 'bedroom', 0.13298035),\n",
       " ('fc', 359, 'wildlife', 0.13276672),\n",
       " ('fc', 28, 'car', 0.13227844),\n",
       " ('fc', 139, 'food', 0.13204956),\n",
       " ('fc', 36, 'wildlife', 0.13150024),\n",
       " ('fc', 148, 'food', 0.1312561),\n",
       " ('fc', 323, 'wildlife', 0.13078308),\n",
       " ('fc', 171, 'ferries', 0.13061523),\n",
       " ('fc', 224, 'wildlife', 0.13031006),\n",
       " ('fc', 345, 'insects', 0.12936401),\n",
       " ('fc', 257, 'car', 0.12902832),\n",
       " ('fc', 29, 'car', 0.12882996),\n",
       " ('fc', 114, 'food', 0.1288147),\n",
       " ('fc', 287, 'wildlife', 0.12876892),\n",
       " ('fc', 356, 'wildlife', 0.12564087),\n",
       " ('fc', 199, 'vehicle', 0.1250763),\n",
       " ('fc', 258, 'wildlife', 0.12374878),\n",
       " ('fc', 341, 'wildlife', 0.12371826),\n",
       " ('fc', 342, 'juvenile', 0.12310791),\n",
       " ('fc', 185, 'foods', 0.122558594),\n",
       " ('fc', 31, 'food', 0.12121582),\n",
       " ('fc', 72, 'food', 0.12072754),\n",
       " ('fc', 151, 'wildlife', 0.12069702),\n",
       " ('fc', 79, 'ferries', 0.120666504),\n",
       " ('fc', 249, 'nature', 0.118774414),\n",
       " ('fc', 191, 'deg', 0.11729431),\n",
       " ('fc', 328, 'bedroom', 0.11621094),\n",
       " ('fc', 23, 'car', 0.11528015),\n",
       " ('fc', 318, 'bookshelf', 0.114868164),\n",
       " ('fc', 215, 'bedroom', 0.11482239),\n",
       " ('fc', 165, 'nature', 0.1146698),\n",
       " ('fc', 71, 'vehicles', 0.113708496),\n",
       " ('fc', 157, 'car', 0.1134491),\n",
       " ('fc', 118, 'desert', 0.11276245),\n",
       " ('fc', 58, 'sailing', 0.11262512),\n",
       " ('fc', 261, 'dog', 0.112213135),\n",
       " ('fc', 47, 'vendors', 0.11218262),\n",
       " ('fc', 39, 'beverage', 0.11148071),\n",
       " ('fc', 247, 'ferries', 0.111328125)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_50_layer_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
