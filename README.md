# neural_networks_explainability

A class project on testing various explainability methods in Neural Networks.

### Network dissect

We utilized the code from https://github.com/Trustworthy-ML-Lab/CLIP-dissect and modified it to work on our dataset (ImageNet subsample) on the range of models we inspect.

The analysis is located in clip_notebook.ipynb.

### LIME

We use the tutorial from https://github.com/marcotcr/lime/blob/master/doc/notebooks/Tutorial%20-%20images%20-%20 Pytorch.ipynb.

The analysis is located in LIME/lime.ipynb.

### GradCAM and variations

We utilize the repository from https://github.com/jacobgil/pytorch-grad-cam

The analysis is located in GradCAM/cam_methods.ipynb.
